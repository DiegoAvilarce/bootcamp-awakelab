{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A confidence interval provides a range of plausible values for the population parameter, whereas a test of significance assesses the likelihood of a specific claim or hypothesis about the population parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### p-value using scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function ttest_1samp in module scipy.stats._stats_py:\n",
      "\n",
      "ttest_1samp(a, popmean, axis=0, nan_policy='propagate', alternative='two-sided')\n",
      "    Calculate the T-test for the mean of ONE group of scores.\n",
      "    \n",
      "    This is a test for the null hypothesis that the expected value\n",
      "    (mean) of a sample of independent observations `a` is equal to the given\n",
      "    population mean, `popmean`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Sample observation.\n",
      "    popmean : float or array_like\n",
      "        Expected value in null hypothesis. If array_like, then it must have the\n",
      "        same shape as `a` excluding the axis dimension.\n",
      "    axis : int or None, optional\n",
      "        Axis along which to compute test; default is 0. If None, compute over\n",
      "        the whole array `a`.\n",
      "    nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
      "        Defines how to handle when input contains nan.\n",
      "        The following options are available (default is 'propagate'):\n",
      "    \n",
      "          * 'propagate': returns nan\n",
      "          * 'raise': throws an error\n",
      "          * 'omit': performs the calculations ignoring nan values\n",
      "    \n",
      "    alternative : {'two-sided', 'less', 'greater'}, optional\n",
      "        Defines the alternative hypothesis.\n",
      "        The following options are available (default is 'two-sided'):\n",
      "    \n",
      "        * 'two-sided': the mean of the underlying distribution of the sample\n",
      "          is different than the given population mean (`popmean`)\n",
      "        * 'less': the mean of the underlying distribution of the sample is\n",
      "          less than the given population mean (`popmean`)\n",
      "        * 'greater': the mean of the underlying distribution of the sample is\n",
      "          greater than the given population mean (`popmean`)\n",
      "    \n",
      "        .. versionadded:: 1.6.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    statistic : float or array\n",
      "        t-statistic.\n",
      "    pvalue : float or array\n",
      "        Two-sided p-value.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from scipy import stats\n",
      "    >>> rng = np.random.default_rng()\n",
      "    >>> rvs = stats.norm.rvs(loc=5, scale=10, size=(50, 2), random_state=rng)\n",
      "    \n",
      "    Test if mean of random sample is equal to true mean, and different mean.\n",
      "    We reject the null hypothesis in the second case and don't reject it in\n",
      "    the first case.\n",
      "    \n",
      "    >>> stats.ttest_1samp(rvs, 5.0)\n",
      "    Ttest_1sampResult(statistic=array([-2.09794637, -1.75977004]), pvalue=array([0.04108952, 0.08468867]))\n",
      "    >>> stats.ttest_1samp(rvs, 0.0)\n",
      "    Ttest_1sampResult(statistic=array([1.64495065, 1.62095307]), pvalue=array([0.10638103, 0.11144602]))\n",
      "    \n",
      "    Examples using axis and non-scalar dimension for population mean.\n",
      "    \n",
      "    >>> result = stats.ttest_1samp(rvs, [5.0, 0.0])\n",
      "    >>> result.statistic\n",
      "    array([-2.09794637,  1.62095307])\n",
      "    >>> result.pvalue\n",
      "    array([0.04108952, 0.11144602])\n",
      "    \n",
      "    >>> result = stats.ttest_1samp(rvs.T, [5.0, 0.0], axis=1)\n",
      "    >>> result.statistic\n",
      "    array([-2.09794637,  1.62095307])\n",
      "    >>> result.pvalue\n",
      "    array([0.04108952, 0.11144602])\n",
      "    \n",
      "    >>> result = stats.ttest_1samp(rvs, [[5.0], [0.0]])\n",
      "    >>> result.statistic\n",
      "    array([[-2.09794637, -1.75977004],\n",
      "           [ 1.64495065,  1.62095307]])\n",
      "    >>> result.pvalue\n",
      "    array([[0.04108952, 0.08468867],\n",
      "           [0.10638103, 0.11144602]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(stats.ttest_1samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject the null hypothesis\n",
      "p-value: 0.00044366689961263965\n"
     ]
    }
   ],
   "source": [
    "# thickness of windshields\n",
    "sample = np.array([4.2, 4.1, 4.3, 4.0, 4.2, 4.4, 4.1, 4.5, 4.2, 4.3])\n",
    "\n",
    "# null hypothesis value\n",
    "null_value = 4\n",
    "\n",
    "# one-sample t-test\n",
    "_, p_value = stats.ttest_1samp(\n",
    "    sample, null_value, alternative='greater'\n",
    ")\n",
    "\n",
    "# significance level (α)\n",
    "alpha = 0.05\n",
    "\n",
    "# Check if the p-value is less than the significance level\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis\")\n",
    "\n",
    "# Print the computed p-value\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fail to reject the null hypothesis\n",
      "p-value: 1.0\n"
     ]
    }
   ],
   "source": [
    "# test scores\n",
    "sample = np.array(\n",
    "    [830, 845, 870, 825, 860, 840, 855, 875, 835, 865]\n",
    ")\n",
    "\n",
    "# Define the null hypothesis value\n",
    "null_value = 850\n",
    "\n",
    "# Perform two-sample t-test\n",
    "_, p_value = stats.ttest_1samp(\n",
    "    sample, null_value\n",
    ")\n",
    "\n",
    "# Define the significance level (α)\n",
    "alpha = 0.05\n",
    "\n",
    "# Check if the p-value is less than the significance level\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis\")\n",
    "\n",
    "# Print the computed p-value\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to compute the p-value?\n",
    "\n",
    "$$ t_c = \\frac{\\bar{x}-\\mu_0}{\\frac{s}{\\sqrt{n}}} $$\n",
    "\n",
    "\n",
    "$$ \\text{p-value} = 2 \\times (1 - cdf(|t_{n-1}|)) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [1.5, 2.0, 2.5]\n",
    "mu_0 = 2.0\n",
    "# Compute the sample mean and standard deviation\n",
    "sample_mean = np.mean(sample)\n",
    "sample_std = np.std(sample, ddof=1)\n",
    "\n",
    "# Compute the t-statistic\n",
    "t_stat = (sample_mean - mu_0) / (sample_std / np.sqrt(len(sample)))\n",
    "\n",
    "# Compute the degrees of freedom\n",
    "df = len(sample) - 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bilateral\n",
    "\n",
    "$$H_0: \\mu = \\mu_0$$\n",
    "$$H_1: \\mu \\neq \\mu_0$$\n",
    "\n",
    "$$Pr\\{|t_{n-1}| > |t_c|\\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Null hypothesis\n",
    "# mu_0 = 2.0\n",
    "# One-sample t-test for mu = mu_0\n",
    "_, p_value_1 = stats.ttest_1samp(sample, mu_0)\n",
    "\n",
    "print(\"p-value:\", p_value_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 1.0\n"
     ]
    }
   ],
   "source": [
    "p_value_1 = 2 * (1 - stats.t.cdf(abs(t_stat), df))\n",
    "print(\"p-value:\", p_value_1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upper\n",
    "\n",
    "$$H_0: \\mu \\leq \\mu_0$$\n",
    "$$H_1: \\mu > \\mu_0$$\n",
    "\n",
    "$$Pr\\{t_{n-1} > t_c\\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.5\n"
     ]
    }
   ],
   "source": [
    "# One-sample t-test for mu <= mu_0\n",
    "t_stat, p_value_2 = stats.ttest_1samp(\n",
    "    sample, mu_0, alternative='less'\n",
    ")\n",
    "\n",
    "print(\"p-value:\", p_value_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Calculate the p-value for mu <= mu_0\n",
    "p_value_2 = stats.t.cdf(t_stat, df)\n",
    "\n",
    "print(\"p-value:\", p_value_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lower\n",
    "\n",
    "$$H_0: \\mu \\geq \\mu_0$$\n",
    "$$H_1: \\mu < \\mu_0$$\n",
    "\n",
    "$$Pr\\{t_{n-1} < t_c\\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.5\n"
     ]
    }
   ],
   "source": [
    "# One-sample t-test for mu >= mu_0\n",
    "t_stat, p_value_3 = stats.ttest_1samp(\n",
    "    sample, mu_0, alternative='greater'\n",
    ")\n",
    "\n",
    "print(\"p-value:\", p_value_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Calculate the p-value for mu >= mu_0\n",
    "p_value_3 = 1 - stats.t.cdf(t_stat, df)\n",
    "\n",
    "print(\"p-value:\", p_value_3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### z-test for a proportion\n",
    "he test statistic z measures the number of standard deviations that the sample proportion is away from the hypothesized proportion.\n",
    "$$\n",
    "z = \\frac{{\\hat{p} - p_0}}{{\\sqrt{\\frac{{p_0(1 - p_0)}}{{n}}}}}\n",
    "$$\n",
    "Where:\n",
    "\n",
    "* z is the test statistic following the standard normal distribution.\n",
    "* \\(\\hat{p}\\) is the sample proportion.\n",
    "* \\(p_0\\) is the hypothesized population proportion under the null hypothesis.\n",
    "* \\(n\\) is the sample size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.06941907499936395\n",
      "Fail to reject the null hypothesis\n"
     ]
    }
   ],
   "source": [
    "# Given information\n",
    "alpha = 0.05\n",
    "p_hypothesized = 0.35\n",
    "sample_size = 300\n",
    "sample_success = 90\n",
    "\n",
    "# Calculate the sample proportion\n",
    "p_sample = sample_success / sample_size\n",
    "\n",
    "# Calculate the standard error\n",
    "se = np.sqrt((p_hypothesized * (1 - p_hypothesized)) / sample_size)\n",
    "\n",
    "# Calculate the test statistic\n",
    "z = (p_sample - p_hypothesized) / se\n",
    "\n",
    "# Calculate the p-value (two-tailed)\n",
    "p_value = 2 * (1 - stats.norm.cdf(np.abs(z)))\n",
    "\n",
    "print(f\"p-value: {p_value}\")\n",
    "\n",
    "# Check if the p-value is less than the significance level\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.946278254943948 2.4048917596601207\n",
      "Reject the lot\n"
     ]
    }
   ],
   "source": [
    "# Given information\n",
    "sample_mean = 750\n",
    "sample_size = 50\n",
    "population_std = 120\n",
    "population_mean = 800\n",
    "significance_level = 0.01\n",
    "\n",
    "# Calculate the test statistic\n",
    "standard_error = population_std / np.sqrt(sample_size)\n",
    "t_value = (sample_mean - population_mean) / standard_error\n",
    "\n",
    "# Calculate the critical value\n",
    "degrees_of_freedom = sample_size - 1\n",
    "critical_value = stats.t.ppf(1 - significance_level, degrees_of_freedom)\n",
    "\n",
    "print(t_value, critical_value)\n",
    "# Compare the test statistic with the critical value\n",
    "if t_value < -critical_value or t_value > critical_value:\n",
    "    print(\"Reject the lot\")\n",
    "else:\n",
    "    print(\"Do not reject the lot\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability of committing a Type II error is equal to 1 minus the cumulative distribution function (CDF) of the test statistic for the alternative hypothesis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of Type II error: 0.9887688839004888\n"
     ]
    }
   ],
   "source": [
    "alternative_mean = 790\n",
    "\n",
    "# Calculate the test statistic for the alternative hypothesis\n",
    "t_value_alt = (sample_mean - alternative_mean) / standard_error\n",
    "\n",
    "# Calculate the p-value for the alternative hypothesis\n",
    "p_value_alt = stats.t.cdf(t_value_alt, degrees_of_freedom)\n",
    "\n",
    "# Calculate the probability of Type II error\n",
    "type_ii_error = 1 - p_value_alt\n",
    "\n",
    "print(f\"Probability of Type II error: {type_ii_error}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions asked in class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 7.707766001215446e-11\n"
     ]
    }
   ],
   "source": [
    "# search for xi test\n",
    "# Observed frequency counts\n",
    "observed = np.array(\n",
    "    [[50, 30], [20, 100]]\n",
    ")\n",
    "\n",
    "# Perform chi-square test\n",
    "_, p_value, _, _ = stats.chi2_contingency(observed)\n",
    "\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
